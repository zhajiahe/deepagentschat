"""
DuckDB æ•°æ®æŸ¥è¯¢å·¥å…·
ç”¨æ³•: python data_query.py "SELECT * FROM 'data.csv'"
"""

import re
import sys
from pathlib import Path

import duckdb


def main():
    # æ£€æŸ¥å‚æ•°
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python data_query.py \"SELECT * FROM 'data.csv'\"")
        print("\nå¸¸ç”¨ç¤ºä¾‹:")
        print("  python data_query.py \"SELECT * FROM 'data.csv' LIMIT 10\"")
        print("  python data_query.py \"SELECT COUNT(*) FROM 'data.csv'\"")
        print("  python data_query.py \"COPY (SELECT * FROM 'data.xlsx') TO 'output.csv'\"")
        sys.exit(1)

    query = sys.argv[1]

    # æ£€æŸ¥å¼•ç”¨çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    check_files_exist(query)

    try:
        con = duckdb.connect()

        # è®¾ç½®åˆç†çš„é»˜è®¤é…ç½®
        con.execute("SET memory_limit='2GB'")
        con.execute("SET threads=4")

        result = con.execute(query)

        # å°è¯•è·å–ç»“æœ
        try:
            df = result.df()

            # ç©ºç»“æœ
            if df.empty:
                print("âš ï¸  æŸ¥è¯¢è¿”å› 0 è¡Œ")
                return

            # è¾“å‡ºç»“æœ
            print_result(df)
        except Exception:
            # DDL/DML è¯­å¥ï¼Œæ— è¿”å›ç»“æœ
            print("âœ… æ‰§è¡ŒæˆåŠŸ")
            return

        con.close()

    except duckdb.CatalogException as e:
        print(f"âŒ è¡¨æˆ–åˆ—ä¸å­˜åœ¨: {e}", file=sys.stderr)
        sys.exit(1)

    except duckdb.ParserException as e:
        print(f"âŒ SQL è¯­æ³•é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)

    except duckdb.IOException as e:
        print(f"âŒ æ–‡ä»¶è¯»å–é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)

    except MemoryError:
        print("âŒ å†…å­˜ä¸è¶³ï¼Œå»ºè®®:", file=sys.stderr)
        print("  1. åœ¨æŸ¥è¯¢æœ«å°¾æ·»åŠ  LIMIT", file=sys.stderr)
        print("  2. ä½¿ç”¨ COPY TO å¯¼å‡º: COPY (...) TO 'output.csv'", file=sys.stderr)
        sys.exit(1)

    except Exception as e:
        print(f"âŒ æ‰§è¡Œé”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def check_files_exist(query: str):
    """æ£€æŸ¥ SQL ä¸­å¼•ç”¨çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    # Skip file check for COPY TO statements (output files don't need to exist)
    if re.search(r"\bCOPY\s*\(.*\)\s*TO\s+", query, re.IGNORECASE):
        return

    # åŒ¹é… 'file.ext' æˆ– "file.ext"
    pattern = r"['\"]([^'\"]+\.(csv|json|parquet|xlsx|xls|jsonl))['\"]"
    files = re.findall(pattern, query, re.IGNORECASE)

    missing = []
    for file_path, _ in files:
        # è·³è¿‡é€šé…ç¬¦
        if "*" in file_path or "?" in file_path:
            continue
        if not Path(file_path).exists():
            missing.append(file_path)

    if missing:
        print("âŒ æ–‡ä»¶ä¸å­˜åœ¨:", file=sys.stderr)
        for f in missing:
            print(f"   {f}", file=sys.stderr)
        sys.exit(1)


def print_result(df):
    """æ™ºèƒ½è¾“å‡ºç»“æœ"""
    rows, cols = len(df), len(df.columns)

    # Convert pandas NA to string 'NULL' for better display compatibility with tabulate
    df = df.astype(str).replace("<NA>", "NULL")

    # å°ç»“æœï¼šç›´æ¥è¾“å‡º markdown è¡¨æ ¼
    if rows <= 1000:
        try:
            from tabulate import tabulate  # type: ignore[import-untyped]

            print(tabulate(df, headers="keys", tablefmt="github", showindex=False))
        except ImportError:
            print(df.to_markdown(index=False))

        # æ˜¾ç¤ºç»Ÿè®¡
        if rows > 50:
            print(f"\nğŸ“Š {rows:,} è¡Œ Ã— {cols} åˆ—")

    # å¤§ç»“æœï¼šåªæ˜¾ç¤ºå‰ 100 è¡Œ + ç»Ÿè®¡
    else:
        print(f"âš ï¸  ç»“æœè¾ƒå¤§ ({rows:,} è¡Œ)ï¼Œä»…æ˜¾ç¤ºå‰ 100 è¡Œ\n")

        try:
            from tabulate import tabulate

            print(tabulate(df.head(100), headers="keys", tablefmt="github", showindex=False))
        except ImportError:
            print(df.head(100).to_markdown(index=False))

        print(f"\nğŸ“Š æ€»è®¡: {rows:,} è¡Œ Ã— {cols} åˆ—")
        print("ğŸ’¡ æç¤º: åœ¨æŸ¥è¯¢æœ«å°¾æ·»åŠ  LIMITï¼Œæˆ–ä½¿ç”¨ COPY TO å¯¼å‡ºå®Œæ•´ç»“æœ")


if __name__ == "__main__":
    main()
