"""
DuckDB æ•°æ®æŸ¥è¯¢å·¥å…·
ç”¨æ³•: python data_query.py "SELECT * FROM 'data.csv'"

æ”¯æŒæ ¼å¼:
- CSV/JSON/Parquet: ç›´æ¥ç”± DuckDB è¯»å–
- Excel (xlsx/xls): ç”± Polars é¢„å¤„ç†åæ³¨å†Œåˆ° DuckDB
"""

import re
import sys
from pathlib import Path

import duckdb
import polars as pl


def main():
    # æ£€æŸ¥å‚æ•°
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python data_query.py \"SELECT * FROM 'data.csv'\"")
        print("\nå¸¸ç”¨ç¤ºä¾‹:")
        print("  python data_query.py \"SELECT * FROM 'data.csv' LIMIT 10\"")
        print("  python data_query.py \"SELECT COUNT(*) FROM 'data.csv'\"")
        print("  python data_query.py \"COPY (SELECT * FROM 'data.xlsx') TO 'output.csv'\"")
        sys.exit(1)

    query = sys.argv[1]

    # æ£€æŸ¥å¼•ç”¨çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    check_files_exist(query)

    try:
        con = duckdb.connect()

        # è®¾ç½®åˆç†çš„é»˜è®¤é…ç½®
        con.execute("SET memory_limit='2GB'")
        con.execute("SET threads=4")

        # é¢„å¤„ç† Excel æ–‡ä»¶å¹¶æ³¨å†Œåˆ° DuckDBï¼ˆè¿”å›ä¿®æ”¹åçš„æŸ¥è¯¢ï¼‰
        query = register_excel_files(con, query)

        result = con.execute(query)

        # å°è¯•è·å–ç»“æœ
        try:
            df = result.df()

            # ç©ºç»“æœ
            if df.empty:
                print("âš ï¸  æŸ¥è¯¢è¿”å› 0 è¡Œ")
                return

            # è¾“å‡ºç»“æœ
            print_result(df)
        except Exception:
            # DDL/DML è¯­å¥ï¼Œæ— è¿”å›ç»“æœ
            print("âœ… æ‰§è¡ŒæˆåŠŸ")
            return

        con.close()

    except duckdb.CatalogException as e:
        print(f"âŒ è¡¨æˆ–åˆ—ä¸å­˜åœ¨: {e}", file=sys.stderr)
        sys.exit(1)

    except duckdb.ParserException as e:
        print(f"âŒ SQL è¯­æ³•é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)

    except duckdb.IOException as e:
        print(f"âŒ æ–‡ä»¶è¯»å–é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)

    except MemoryError:
        print("âŒ å†…å­˜ä¸è¶³ï¼Œå»ºè®®:", file=sys.stderr)
        print("  1. åœ¨æŸ¥è¯¢æœ«å°¾æ·»åŠ  LIMIT", file=sys.stderr)
        print("  2. ä½¿ç”¨ COPY TO å¯¼å‡º: COPY (...) TO 'output.csv'", file=sys.stderr)
        sys.exit(1)

    except Exception as e:
        print(f"âŒ æ‰§è¡Œé”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


def register_excel_files(con: duckdb.DuckDBPyConnection, query: str) -> str:
    """ä½¿ç”¨ Polars é¢„å¤„ç† Excel æ–‡ä»¶å¹¶æ³¨å†Œåˆ° DuckDB

    Returns:
        ä¿®æ”¹åçš„æŸ¥è¯¢è¯­å¥ï¼ˆå°† Excel æ–‡ä»¶è·¯å¾„æ›¿æ¢ä¸ºè¡¨åï¼‰
    """
    # åŒ¹é… Excel æ–‡ä»¶è·¯å¾„
    pattern = r"['\"]([^'\"]+\.(xlsx|xls))['\"]"
    excel_files = re.findall(pattern, query, re.IGNORECASE)

    modified_query = query

    for file_path, _ in excel_files:
        # è·³è¿‡é€šé…ç¬¦
        if "*" in file_path or "?" in file_path:
            continue

        if not Path(file_path).exists():
            continue

        try:
            # ä½¿ç”¨ Polars è¯»å– Excel æ–‡ä»¶
            print(f"ğŸ“Š ä½¿ç”¨ Polars é¢„å¤„ç†: {file_path}")
            df_polars = pl.read_excel(file_path)

            # è½¬æ¢ä¸º Pandas DataFrame (DuckDB å…¼å®¹æ€§æ›´å¥½)
            df_pandas = df_polars.to_pandas()

            # ç”Ÿæˆè¡¨å (ç§»é™¤è·¯å¾„å’Œæ‰©å±•å)
            table_name = Path(file_path).stem

            # æ³¨å†Œåˆ° DuckDB
            con.register(table_name, df_pandas)
            print(f"âœ… å·²æ³¨å†Œè¡¨: {table_name} ({len(df_pandas)} è¡Œ Ã— {len(df_pandas.columns)} åˆ—)\n")

            # æ›¿æ¢æŸ¥è¯¢ä¸­çš„æ–‡ä»¶è·¯å¾„ä¸ºè¡¨å
            # åŒ¹é…å¸¦å¼•å·çš„æ–‡ä»¶è·¯å¾„
            modified_query = re.sub(
                rf"['\"]({re.escape(file_path)})['\"]",
                table_name,
                modified_query,
                flags=re.IGNORECASE,
            )

        except Exception as e:
            print(f"âš ï¸  é¢„å¤„ç† {file_path} å¤±è´¥: {e}", file=sys.stderr)
            continue

    return modified_query


def check_files_exist(query: str):
    """æ£€æŸ¥ SQL ä¸­å¼•ç”¨çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    # Skip file check for COPY TO statements (output files don't need to exist)
    if re.search(r"\bCOPY\s*\(.*\)\s*TO\s+", query, re.IGNORECASE):
        return

    # åŒ¹é… 'file.ext' æˆ– "file.ext"
    pattern = r"['\"]([^'\"]+\.(csv|json|parquet|xlsx|xls|jsonl))['\"]"
    files = re.findall(pattern, query, re.IGNORECASE)

    missing = []
    for file_path, _ in files:
        # è·³è¿‡é€šé…ç¬¦
        if "*" in file_path or "?" in file_path:
            continue
        if not Path(file_path).exists():
            missing.append(file_path)

    if missing:
        print("âŒ æ–‡ä»¶ä¸å­˜åœ¨:", file=sys.stderr)
        for f in missing:
            print(f"   {f}", file=sys.stderr)
        sys.exit(1)


def print_result(df):
    """æ™ºèƒ½è¾“å‡ºç»“æœ"""
    rows, cols = len(df), len(df.columns)

    # Convert pandas NA to string 'NULL' for better display compatibility with tabulate
    df = df.astype(str).replace("<NA>", "NULL")

    # å°ç»“æœï¼šç›´æ¥è¾“å‡º markdown è¡¨æ ¼
    if rows <= 1000:
        try:
            from tabulate import tabulate  # type: ignore[import-untyped]

            print(tabulate(df, headers="keys", tablefmt="github", showindex=False))
        except ImportError:
            print(df.to_markdown(index=False))

        # æ˜¾ç¤ºç»Ÿè®¡
        if rows > 50:
            print(f"\nğŸ“Š {rows:,} è¡Œ Ã— {cols} åˆ—")

    # å¤§ç»“æœï¼šåªæ˜¾ç¤ºå‰ 100 è¡Œ + ç»Ÿè®¡
    else:
        print(f"âš ï¸  ç»“æœè¾ƒå¤§ ({rows:,} è¡Œ)ï¼Œä»…æ˜¾ç¤ºå‰ 100 è¡Œ\n")

        try:
            from tabulate import tabulate

            print(tabulate(df.head(100), headers="keys", tablefmt="github", showindex=False))
        except ImportError:
            print(df.head(100).to_markdown(index=False))

        print(f"\nğŸ“Š æ€»è®¡: {rows:,} è¡Œ Ã— {cols} åˆ—")
        print("ğŸ’¡ æç¤º: åœ¨æŸ¥è¯¢æœ«å°¾æ·»åŠ  LIMITï¼Œæˆ–ä½¿ç”¨ COPY TO å¯¼å‡ºå®Œæ•´ç»“æœ")


if __name__ == "__main__":
    main()
