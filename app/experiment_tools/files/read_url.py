"""
URL å†…å®¹è¯»å–å·¥å…·
ç”¨æ³•: python read_url.py <url> [options]
"""

import argparse
import socket
import ssl
import sys
from pathlib import Path
from urllib.error import HTTPError, URLError
from urllib.parse import urlparse
from urllib.request import Request, urlopen

# å¸¸é‡é…ç½®
MAX_CONTENT_SIZE = 10 * 1024 * 1024  # 10MB
MAX_DISPLAY_CHARS = 5000
DEFAULT_TIMEOUT = 30
USER_AGENT = "Mozilla/5.0 (compatible; AI-DB-Tools/1.0)"


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="è¯»å–å¹¶æ˜¾ç¤º URL å†…å®¹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python read_url.py https://example.com
  python read_url.py https://api.github.com/repos/python/cpython --timeout 60
  python read_url.py https://example.com --max-size 5000000
  python read_url.py https://example.com --save output.html
  python read_url.py https://example.com --headers "Authorization: Bearer token"
        """,
    )

    parser.add_argument("url", help="è¦è¯»å–çš„ URL")
    parser.add_argument(
        "--timeout", type=int, default=DEFAULT_TIMEOUT, help=f"è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ {DEFAULT_TIMEOUT}"
    )
    parser.add_argument(
        "--max-size", type=int, default=MAX_CONTENT_SIZE, help=f"æœ€å¤§å†…å®¹å¤§å°ï¼ˆå­—èŠ‚ï¼‰ï¼Œé»˜è®¤ {MAX_CONTENT_SIZE}"
    )
    parser.add_argument(
        "--max-display", type=int, default=MAX_DISPLAY_CHARS, help=f"æœ€å¤§æ˜¾ç¤ºå­—ç¬¦æ•°ï¼Œé»˜è®¤ {MAX_DISPLAY_CHARS}"
    )
    parser.add_argument("--save", type=str, help="ä¿å­˜å†…å®¹åˆ°æ–‡ä»¶")
    parser.add_argument("--headers", action="append", help='æ·»åŠ  HTTP è¯·æ±‚å¤´ï¼ˆæ ¼å¼: "Key: Value"ï¼‰')
    parser.add_argument("--no-verify-ssl", action="store_true", help="è·³è¿‡ SSL è¯ä¹¦éªŒè¯ï¼ˆä¸æ¨èï¼‰")
    parser.add_argument("--follow-redirects", action="store_true", default=True, help="è·Ÿéšé‡å®šå‘ï¼ˆé»˜è®¤å¯ç”¨ï¼‰")
    parser.add_argument("--show-headers", action="store_true", help="æ˜¾ç¤ºå“åº”å¤´ä¿¡æ¯")

    return parser.parse_args()


def validate_url(url: str) -> bool:
    """éªŒè¯ URL æ ¼å¼"""
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc]) and result.scheme in ["http", "https"]
    except Exception:
        return False


def get_content_type(headers) -> str:  # type: ignore[no-untyped-def]
    """è·å–å†…å®¹ç±»å‹"""
    content_type = str(headers.get("Content-Type", ""))
    if ";" in content_type:
        content_type = content_type.split(";")[0].strip()
    return content_type


def is_text_content(content_type: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºæ–‡æœ¬å†…å®¹"""
    text_types = ["text/", "application/json", "application/xml", "application/javascript", "application/x-yaml"]
    return any(content_type.startswith(t) for t in text_types)


def detect_encoding(headers, content: bytes) -> str:  # type: ignore[no-untyped-def]
    """æ£€æµ‹å†…å®¹ç¼–ç """
    # 1. ä» Content-Type header è·å–
    content_type = str(headers.get("Content-Type", ""))
    if "charset=" in content_type:
        charset = content_type.split("charset=")[-1].split(";")[0].strip()
        return charset

    # 2. ä» HTML meta æ ‡ç­¾æ£€æµ‹
    try:
        content_str = content[:1024].decode("utf-8", errors="ignore")
        if "charset=" in content_str.lower():
            import re

            match = re.search(r'charset=["\']?([^"\'>\s]+)', content_str, re.IGNORECASE)
            if match:
                return match.group(1)
    except Exception:
        pass

    # 3. é»˜è®¤ä½¿ç”¨ utf-8
    return "utf-8"


def format_size(size_bytes: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    size_float = float(size_bytes)
    for unit in ["B", "KB", "MB", "GB"]:
        if size_float < 1024.0:
            return f"{size_float:.1f} {unit}"
        size_float /= 1024.0
    return f"{size_float:.1f} TB"


def read_url(url: str, args) -> tuple:
    """
    è¯»å– URL å†…å®¹
    è¿”å›: (content, headers, status_code)
    """
    # åˆ›å»ºè¯·æ±‚
    request = Request(url)
    request.add_header("User-Agent", USER_AGENT)

    # æ·»åŠ è‡ªå®šä¹‰è¯·æ±‚å¤´
    if args.headers:
        for header in args.headers:
            if ":" in header:
                key, value = header.split(":", 1)
                request.add_header(key.strip(), value.strip())

    # SSL ä¸Šä¸‹æ–‡
    context = None
    if args.no_verify_ssl:
        context = ssl._create_unverified_context()
        print("âš ï¸  è­¦å‘Š: SSL è¯ä¹¦éªŒè¯å·²ç¦ç”¨", file=sys.stderr)

    # å‘é€è¯·æ±‚
    try:
        response = urlopen(request, timeout=args.timeout, context=context)
    except HTTPError as e:
        raise Exception(f"HTTP é”™è¯¯ {e.code}: {e.reason}") from e
    except URLError as e:
        if isinstance(e.reason, socket.timeout):
            raise Exception(f"è¯·æ±‚è¶…æ—¶ï¼ˆ{args.timeout}ç§’ï¼‰") from e
        raise Exception(f"URL é”™è¯¯: {e.reason}") from e
    except TimeoutError as e:
        raise Exception(f"è¿æ¥è¶…æ—¶ï¼ˆ{args.timeout}ç§’ï¼‰") from e

    # æ£€æŸ¥å†…å®¹å¤§å°
    content_length = response.headers.get("Content-Length")
    if content_length:
        size = int(content_length)
        if size > args.max_size:
            raise Exception(f"å†…å®¹è¿‡å¤§ ({format_size(size)})ï¼Œè¶…è¿‡é™åˆ¶ ({format_size(args.max_size)})")

    # è¯»å–å†…å®¹
    content = b""
    chunk_size = 8192
    total_read = 0

    while True:
        chunk = response.read(chunk_size)
        if not chunk:
            break

        content += chunk
        total_read += len(chunk)

        if total_read > args.max_size:
            raise Exception(f"å†…å®¹è¶…è¿‡å¤§å°é™åˆ¶ ({format_size(args.max_size)})")

    return content, response.headers, response.getcode()


def display_content(content: bytes, headers, args):
    """æ˜¾ç¤ºå†…å®¹"""
    content_type = get_content_type(headers)

    # æ˜¾ç¤ºå“åº”å¤´
    if args.show_headers:
        print("=" * 60)
        print("å“åº”å¤´:")
        print("=" * 60)
        for key, value in headers.items():
            print(f"{key}: {value}")
        print("=" * 60)
        print()

    # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡æœ¬å†…å®¹
    if not is_text_content(content_type):
        print(f"âš ï¸  éæ–‡æœ¬å†…å®¹ç±»å‹: {content_type}")
        print(f"ğŸ“¦ å†…å®¹å¤§å°: {format_size(len(content))}")

        if args.save:
            print("ğŸ’¡ ä½¿ç”¨ --save é€‰é¡¹ä¿å­˜åˆ°æ–‡ä»¶")
        else:
            print("ğŸ’¡ å»ºè®®ä½¿ç”¨ --save é€‰é¡¹ä¿å­˜äºŒè¿›åˆ¶å†…å®¹")
        return

    # è§£ç æ–‡æœ¬å†…å®¹
    encoding = detect_encoding(headers, content)

    try:
        text = content.decode(encoding)
    except UnicodeDecodeError:
        # å°è¯•å…¶ä»–ç¼–ç 
        for fallback_encoding in ["utf-8", "gbk", "gb2312", "latin-1"]:
            try:
                text = content.decode(fallback_encoding)
                encoding = fallback_encoding
                print(f"â„¹ï¸  ä½¿ç”¨ç¼–ç : {encoding}", file=sys.stderr)
                break
            except UnicodeDecodeError:
                continue
        else:
            raise Exception("æ— æ³•è§£ç å†…å®¹ï¼Œå°è¯•äº†å¤šç§ç¼–ç ")

    # æ˜¾ç¤ºå†…å®¹
    if len(text) > args.max_display:
        print(text[: args.max_display])
        print(f"\n... [å·²æˆªæ–­. æ€»é•¿åº¦: {len(text):,} å­—ç¬¦ / {format_size(len(content))}]")
        print(f"ğŸ’¡ ä½¿ç”¨ --max-display {len(text)} æŸ¥çœ‹å®Œæ•´å†…å®¹")
        print("ğŸ’¡ æˆ–ä½¿ç”¨ --save ä¿å­˜åˆ°æ–‡ä»¶")
    else:
        print(text)

        if len(text) > 1000:
            print(f"\nğŸ“Š {len(text):,} å­—ç¬¦ / {format_size(len(content))}")


def save_content(content: bytes, filepath: str):
    """ä¿å­˜å†…å®¹åˆ°æ–‡ä»¶"""
    try:
        output_path = Path(filepath)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, "wb") as f:
            f.write(content)

        print(f"âœ… å·²ä¿å­˜åˆ°: {output_path.absolute()}")
        print(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {format_size(len(content))}")
    except Exception as e:
        raise Exception(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}") from e


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()

    # éªŒè¯ URL
    if not validate_url(args.url):
        print("âŒ æ— æ•ˆçš„ URL æ ¼å¼", file=sys.stderr)
        print("ğŸ’¡ URL å¿…é¡»ä»¥ http:// æˆ– https:// å¼€å¤´", file=sys.stderr)
        sys.exit(1)

    # æ˜¾ç¤ºè¯·æ±‚ä¿¡æ¯
    print(f"ğŸŒ æ­£åœ¨è¯·æ±‚: {args.url}", file=sys.stderr)

    try:
        # è¯»å– URL
        content, headers, status_code = read_url(args.url, args)

        print(f"âœ… HTTP {status_code}", file=sys.stderr)
        print(f"ğŸ“¦ å¤§å°: {format_size(len(content))}", file=sys.stderr)
        print(f"ğŸ“„ ç±»å‹: {get_content_type(headers)}", file=sys.stderr)
        print(file=sys.stderr)

        # ä¿å­˜æˆ–æ˜¾ç¤º
        if args.save:
            save_content(content, args.save)
        else:
            display_content(content, headers, args)

    except KeyboardInterrupt:
        print("\nâŒ ç”¨æˆ·ä¸­æ–­", file=sys.stderr)
        sys.exit(1)

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
